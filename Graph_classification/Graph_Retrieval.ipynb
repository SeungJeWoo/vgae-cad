{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n",
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing...\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from GCN import *\n",
    "from utils.math_distances import cosine_distance\n",
    "from utils.my_utils import *\n",
    "from utils.util import *\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import os\n",
    "import time\n",
    "from train_utils import get_batch_data\n",
    "\n",
    "torch.manual_seed(124)\n",
    "np.random.seed(124)\n",
    "\n",
    "print(\"Finished Importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings\n",
      "Using model at path: ../results/runs_GCN/Test_dataset/Models/Test_dataset_09-30\n",
      "The calculations will be performed on the device: cuda:0\n",
      "Results will be saved in: C:\\Users\\sjwoo\\3D_STEP_Classification\\results\\retrieval_GCN\\Test_dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings\")\n",
    "\n",
    "run_folder=\"../\"\n",
    "dataset = \"Test_dataset\"\n",
    "STEP_dataset = dataset + \"/STEP_models/\"\n",
    "graphml_dataset = dataset + \"/graphml_models/\"\n",
    "learning_rate=0.0005\n",
    "batch_size=1\n",
    "num_epochs=1\n",
    "dropout=0.5\n",
    "model_name = \"Test_dataset_09-30\" # \"Name of the model trained in train files\"\n",
    "model_path = \"../results/runs_GCN/Test_dataset/Models/\" + model_name\n",
    "\n",
    "print(\"Using model at path:\", model_path)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"The calculations will be performed on the device:\", device)\n",
    "\n",
    "# save paths\n",
    "out_dir = os.path.abspath(os.path.join(run_folder, \"./results/retrieval_GCN\", dataset))\n",
    "print(\"Results will be saved in:\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph data...\n",
      "dataset_path: ../Datasets/Test_dataset/graphml_models//\n",
      "Loading class: 0\n",
      "Loading class: 1\n",
      "Loading class: 2\n",
      "Loading class: 3\n",
      "Loading class: 4\n",
      "Loading class: 5\n",
      "# classes: 6\n",
      "# maximum node tag: 72\n",
      "# data: 60\n",
      "# training graphs:  48\n",
      "class: 0  - num elements: 8  - elements:  ['0_99.graphml.xml', '0_97.graphml.xml', '0_101.graphml.xml', '0_100.graphml.xml', '0_95.graphml.xml', '0_93.graphml.xml', '0_92.graphml.xml', '0_96.graphml.xml']\n",
      "class: 1  - num elements: 8  - elements:  ['1_98.graphml.xml', '1_94.graphml.xml', '1_95.graphml.xml', '1_100.graphml.xml', '1_99.graphml.xml', '1_102.graphml.xml', '1_97.graphml.xml', '1_101.graphml.xml']\n",
      "class: 2  - num elements: 8  - elements:  ['2_141.graphml.xml', '2_134.graphml.xml', '2_132.graphml.xml', '2_130.graphml.xml', '2_135.graphml.xml', '2_127.graphml.xml', '2_128.graphml.xml', '2_131.graphml.xml']\n",
      "class: 3  - num elements: 8  - elements:  ['3_98.graphml.xml', '3_95.graphml.xml', '3_94.graphml.xml', '3_102.graphml.xml', '3_96.graphml.xml', '3_100.graphml.xml', '3_101.graphml.xml', '3_99.graphml.xml']\n",
      "class: 4  - num elements: 8  - elements:  ['4_98.graphml.xml', '4_91.graphml.xml', '4_94.graphml.xml', '4_92.graphml.xml', '4_99.graphml.xml', '4_96.graphml.xml', '4_93.graphml.xml', '4_90.graphml.xml']\n",
      "class: 5  - num elements: 8  - elements:  ['5_150.graphml.xml', '5_152.graphml.xml', '5_149.graphml.xml', '5_154.graphml.xml', '5_148.graphml.xml', '5_151.graphml.xml', '5_117.graphml.xml', '5_155.graphml.xml']\n",
      "# validation graphs:  6\n",
      "class: 0  - num elements: 1  - elements:  ['0_94.graphml.xml']\n",
      "class: 1  - num elements: 1  - elements:  ['1_93.graphml.xml']\n",
      "class: 2  - num elements: 1  - elements:  ['2_129.graphml.xml']\n",
      "class: 3  - num elements: 1  - elements:  ['3_103.graphml.xml']\n",
      "class: 4  - num elements: 1  - elements:  ['4_97.graphml.xml']\n",
      "class: 5  - num elements: 1  - elements:  ['5_156.graphml.xml']\n",
      "# test graphs:  6\n",
      "class: 0  - num elements: 1  - elements:  ['0_98.graphml.xml']\n",
      "class: 1  - num elements: 1  - elements:  ['1_96.graphml.xml']\n",
      "class: 2  - num elements: 1  - elements:  ['2_133.graphml.xml']\n",
      "class: 3  - num elements: 1  - elements:  ['3_97.graphml.xml']\n",
      "class: 4  - num elements: 1  - elements:  ['4_95.graphml.xml']\n",
      "class: 5  - num elements: 1  - elements:  ['5_157.graphml.xml']\n",
      "Loading data... finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Graph data...\")\n",
    "use_degree_as_tag = False\n",
    "fold = 0\n",
    "graphs, num_classes = my_load_data(graphml_dataset, use_degree_as_tag)\n",
    "\n",
    "train_graphs, test_graphs = separate_data(graphs, fold)\n",
    "train_graphs, valid_graphs = split_data(train_graphs, perc=0.9)\n",
    "print(\"# training graphs: \", len(train_graphs))\n",
    "print_data_commposition(train_graphs)\n",
    "print(\"# validation graphs: \", len(valid_graphs))\n",
    "print_data_commposition(valid_graphs)\n",
    "print(\"# test graphs: \", len(test_graphs))\n",
    "print_data_commposition(test_graphs)\n",
    "# Num of different STEP entities founded in the graph dataset\n",
    "feature_dim_size = graphs[0].node_features.shape[1]\n",
    "print(\"Loading data... finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "72\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GCN_CN_v4:\n\tsize mismatch for convolution_1.lin.weight: copying a param with shape torch.Size([64, 80]) from checkpoint, the shape in current model is torch.Size([64, 72]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_dim_size)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN_CN_v4(feature_dim_size\u001b[38;5;241m=\u001b[39mfeature_dim_size, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, dropout\u001b[38;5;241m=\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m children_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n,c \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_children():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\3D_STEP_Classification\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GCN_CN_v4:\n\tsize mismatch for convolution_1.lin.weight: copying a param with shape torch.Size([64, 80]) from checkpoint, the shape in current model is torch.Size([64, 72])."
     ]
    }
   ],
   "source": [
    "print(\"Creating model\")\n",
    "print(feature_dim_size)\n",
    "model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "children_counter = 0\n",
    "for n,c in model.named_children():\n",
    "    print(\"Children Counter: \",children_counter,\" Layer Name: \",n,)\n",
    "    children_counter+=1\n",
    "output_layer = \"attention\"\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = model\n",
    "        self.pretrained.eval()\n",
    "\n",
    "        self.net = list(self.pretrained.children())[:]#-2\n",
    "        self.pretrained = None\n",
    "\n",
    "    def forward(self, adj, features):\n",
    "        features = self.net[0](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[1](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[2](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        scores = self.net[3](features)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        scores = nn.functional.relu(self.net[4](scores))\n",
    "        scores = self.net[5](scores)\n",
    "        scores = F.log_softmax(scores, dim=1)\n",
    "        return scores\n",
    "\n",
    "\n",
    "retrieval_model = feature_extractor()\n",
    "retrieval_model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2)\n",
      "Mean time: 0.0048748453458150225\n"
     ]
    }
   ],
   "source": [
    "num_graphs = len(graphs)\n",
    "# Get the size of the feature we are using\n",
    "feat_size = output_shape = num_classes\n",
    "# Preallocate the matrix for storing all the features\n",
    "all_feats = np.zeros((num_graphs, feat_size))\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_graphs)\n",
    "    for i in range(0, len(graphs), batch_size):\n",
    "        sampled_idx = idx[i:i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_all_graphs = [graphs[j] for j in sampled_idx]\n",
    "        all_X_concat, all_graph_labels, all_adj = get_batch_data(batch_all_graphs, device)\n",
    "        start_time = time.time()\n",
    "        features = retrieval_model(all_adj, all_X_concat)\n",
    "\n",
    "        times.append(time.time()-start_time)\n",
    "\n",
    "        all_feats[i] = np.array(features.cpu())\n",
    "print(all_feats.shape)\n",
    "\n",
    "print(\"Mean time:\", np.mean(np.array(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "num_queries = len(test_graphs)\n",
    "# Preallocate the matrix for storing all the features for the queries\n",
    "query_feats = np.zeros((num_queries, feat_size))\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_queries)\n",
    "    for i in range(0, len(test_graphs), batch_size):\n",
    "        sampled_idx = idx[i:i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_test_graphs = [test_graphs[j] for j in sampled_idx]\n",
    "        test_X_concat, test_graph_labels, test_adj = get_batch_data(batch_test_graphs, device=device)\n",
    "        features = retrieval_model(test_adj, test_X_concat)\n",
    "        query_feats[i] = np.array(features.cpu())\n",
    "print(query_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n",
      "(3, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "metric = \"cosine\"\n",
    "nbrs = NearestNeighbors(n_neighbors=num_graphs, algorithm ='auto', metric=metric).fit(all_feats)\n",
    "distances, indices = nbrs.kneighbors(query_feats)\n",
    "\n",
    "print(distances.shape)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect mean AP = 1.000\n",
      "mean AP = 0.891\n"
     ]
    }
   ],
   "source": [
    "#this function create a perfect ranking :)\n",
    "def make_perfect_holidays_result(graphs, q_ids):\n",
    "    perfect_idx =[]\n",
    "    for qimno in q_ids:\n",
    "        this_g = graphs[qimno]\n",
    "        positive_results = set([i for i, gh in enumerate(graphs) if (gh.label == this_g.label)])\n",
    "        ok=[qimno]+[i for i in  positive_results]\n",
    "        others = [i for i in range(1491) if i not in positive_results and i != qimno]\n",
    "        perfect_idx.append(ok+others)\n",
    "    return np.array(perfect_idx)\n",
    "\n",
    "def mAP(q_ids, idx, plot=False):\n",
    "    aps = []\n",
    "    precision_recall_x_class = {}\n",
    "    for qimno, qres in zip(q_ids, idx):\n",
    "        this_g = graphs[qimno]\n",
    "        # collect the positive results in the dataset\n",
    "        # the positives have the same prefix as the query image\n",
    "        positive_results = set([i for i, gh in enumerate(graphs) if (gh.label == this_g.label)])\n",
    "        #\n",
    "        # ranks of positives. We skip the result #0, assumed to be the query image\n",
    "        ranks = [i for i, res in enumerate(qres[1:]) if res in positive_results]\n",
    "        #\n",
    "        # accumulate trapezoids with this basis\n",
    "        recall_step = 1.0 / len(positive_results)\n",
    "        ap = 0\n",
    "\n",
    "        for ntp, rank in enumerate(ranks):\n",
    "            # ntp = nb of true positives so far\n",
    "            # rank = nb of retrieved items so far\n",
    "            # y-size on left side of trapezoid:\n",
    "            precision_0 = ntp/float(rank) if rank > 0 else 1.0\n",
    "            # y-size on right side of trapezoid:\n",
    "            precision_1 = (ntp + 1) / float(rank + 1)\n",
    "            ap += (precision_1 + precision_0) * recall_step / 2.0\n",
    "\n",
    "        aps.append(ap)\n",
    "\n",
    "    return np.mean(aps)\n",
    "\n",
    "query_imids = []\n",
    "test_names = [g.name_graph for g in test_graphs]\n",
    "for i, g in enumerate(graphs):\n",
    "    if g.name_graph in test_names:\n",
    "        query_imids.append(i)\n",
    "\n",
    "perfect_result = make_perfect_holidays_result(graphs, query_imids)\n",
    "p_map = mAP(query_imids,perfect_result)\n",
    "print('Perfect mean AP = %.3f'%p_map)\n",
    "map = mAP(query_imids, indices, True)\n",
    "print('mean AP = %.3f'%map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(out_dir + \"/mAP_retrival.txt\", 'a') as f:\n",
    "    if isinstance(metric, str):\n",
    "        metric_name = metric\n",
    "    else:\n",
    "        metric_name = metric.__name__\n",
    "    f.write(\"Model: \"+ str(model.__class__.__name__) + \", metric: \"+ metric_name + \", out_layer dim:\" + str(output_shape) + \", mAP: \"+ str(map)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
